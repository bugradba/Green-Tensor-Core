# ğŸŒ¿ Green-Tensor-Core

**Sustainable Hybrid (CPU + PIM) Computing Architecture for Next-Gen AI Workloads**

> *"Moving the processor to the data, instead of moving data to the processor."*

[View Demo](#) â€¢ [Documentation](#) â€¢ [Report Bug](#)

---

## ğŸš€ Executive Summary

**Green-Tensor-Core** is a simulation framework for a **Hybrid Computing Architecture** designed to tackle one of the biggest challenges in modern computing: **Data Movement Energy Costs**.

In traditional Von Neumann architectures, up to **62.7% of total system energy** is wasted on moving data between **Memory (DRAM)** and the **Processor (CPU/GPU)**.  
This project proposes a sustainable solution by integrating **Processing-in-Memory (PIM)** accelerators with a host CPU.

By offloading heavy **vector-matrix operations** to the memory module and keeping control logic on the CPU, **Green-Tensor-Core** aims to drastically reduce the **carbon footprint** of:

- 5G/6G Networks  
- Green Data Centers  
- Autonomous Systems  
- Edge AI & IoT Devices  

---

## ğŸ§  System Architecture

The system follows a **heterogeneous computing model** with three main layers:

> ğŸ“Œ *(Place your architecture diagram in `docs/architecture_diagram.png` and reference it here)*

### 1. Host CPU (Control Plane)

- **Role:** Manages OS, I/O requests, and light serial processing  
- **Logic:** Acts as the *"brain"* and decides which tasks should be offloaded  

### 2. PIM Accelerator (Data Plane)

- **Role:** Performs high-intensity parallel computations (e.g., Deep Learning Inference, FFT) directly inside memory  
- **Benefit:** Near-zero data movement cost for large datasets  

### 3. Intelligent Hybrid Scheduler âš¡

**Core Innovation:**  
A runtime scheduler that analyzes incoming tasks:

- If task is **Data-Intensive** (e.g., Matrix Multiplication) â†’ Offload to **PIM**
- If task is **Control-Intensive** (e.g., Branching Logic) â†’ Execute on **CPU**

---

## ğŸŒ Potential Use Cases

| Domain | Problem | Green-Tensor-Core Solution |
|--------|---------|----------------------------|
| ğŸ“¡ 5G & 6G Networks | Base stations consume massive power for signal processing | Reduces energy per bit via in-memory processing |
| â˜ï¸ Green Data Centers | AI training (LLMs) causes high heat & carbon emissions | Lowers cooling cost and TDP |
| ğŸ›¸ Autonomous Systems | Limited battery for AI workloads | Extends flight time / driving range |
| ğŸ”’ Edge AI & IoT | Cloud offloading is slow and risky | Enables secure, low-latency on-device AI |

---

## ğŸ“Š Simulation Results

Benchmarked against **CPU-only architectures** using synthetic workloads (ResNet-50-like matrix operations):

- âš¡ **Energy Savings:** ~**42%** reduction in total energy consumption  
- â±ï¸ **Latency:** **1.8Ã— speedup** for large batch workloads  
- ğŸ“‰ **Bus Utilization:** **60% reduction** in memory bus traffic  

---

## ğŸ› ï¸ Installation & Quick Start

### Prerequisites

- Python **3.8+**
- `pip`

### Steps

#### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/bugradba/Green-Tensor-Core.git
cd Green-Tensor-Core
pip install -r requirements.txt
python src/main.py --mode hybrid --workload large_matrix


Green-Tensor-Core/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/       # CPU, PIM, Memory models
â”‚   â”œâ”€â”€ scheduler/        # Task offloading logic
â”‚   â”œâ”€â”€ analysis/         # Energy profiling tools
â”‚   â””â”€â”€ main.py           # Entry point
â”œâ”€â”€ notebooks/            # Visualization & analysis notebooks
â”œâ”€â”€ docs/                 # Diagrams and references
â”œâ”€â”€ tests/                # Unit tests
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


ğŸ¤ Contact & Acknowledgements

Developer: Muhammed BuÄŸra DemirbaÅŸ
Context: Developed for Tomorrow's Technology Leaders (Sustainability Track).

LinkedIn: https://www.linkedin.com/in/m-bugra-demirbas/

Email: mbugrademirbas@gmail.com



